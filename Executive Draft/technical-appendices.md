# California Enterprise Modernization Plan
## Technical Appendices

**Prepared for:** Governor's Office, Office of Data and Innovation, Government Operations Agency
**Date:** December 2025
**Version:** Executive Draft v1.0

---

> This document is part of the California Enterprise Modernization recommendation. See also:
> - [Governance Model](governance-model.md) — E3 structure, leadership roles, and data governance
> - [Talent Development](talent-development.md) — Fellowship program and workforce development
> - [Funding & Implementation](funding-implementation.md) — Breakthrough Fund and implementation roadmap
> - [Procurement Guide](procurement-guide.md) — Technology and procurement innovation
> - [Operational Appendices](operational-appendices.md) — Templates and operational guides

---

## Table of Contents

- [Appendix B: Technology Standards Catalog](#appendix-b-technology-standards-catalog)
- [Appendix C: Readiness Assessment Framework](#appendix-c-readiness-assessment-framework)
- [Appendix D: Glossary](#appendix-d-glossary)
- [Appendix E: References and Source Documents](#appendix-e-references-and-source-documents)
- [Appendix F: Budget and Financial Models](#appendix-f-budget-and-financial-models)
- [Appendix G: Performance and Change Management Framework](#appendix-g-performance-and-change-management-framework)
  - G.8 Risk Mitigation Matrix
- [Appendix H: Technology Architecture Details](#appendix-h-technology-architecture-details)
  - H.1 API Management Strategy
  - H.2 Legacy System Modernization
  - H.3 Cloud Strategy
  - H.4 Cybersecurity Architecture
  - H.5 Staff Empowerment for Agentic Data Systems
  - H.6 Technology Standards Catalog

---

## Appendix B: Technology Standards Catalog

*Note: Technology Standards have been consolidated into [Appendix H: Technology Architecture Details](#appendix-h-technology-architecture-details), Section H.6. See Appendix H for comprehensive API standards, data exchange standards, cybersecurity standards, and cloud standards.*

---

## Appendix C: Readiness Assessment Framework

> **Note:** The complete Readiness Assessment Framework has been moved to a dedicated folder for easier use and maintenance. This appendix provides a summary; see the full documentation below.

**Full Documentation:**
- [Readiness Assessment Guide](readiness-assessment/readiness-assessment-guide.md) — Strategic rationale, conceptual foundations, and implementation procedures
- [Enhanced Readiness Assessment](readiness-assessment/enhanced-readiness-assessment.md) — Complete assessment instrument with detailed scoring rubrics

### C.1 Assessment Domains (Summary)

The assessment evaluates six critical domains:

| Domain | Weight | Key Indicators |
|--------|--------|----------------|
| **1. Leadership and Governance** | 20% | Executive sponsorship, IT strategic alignment, governance structures |
| **2. Data and Technology Infrastructure** | 20% | Cloud adoption, API/interoperability, data governance |
| **3. Organizational Culture and Workforce** | 15% | Change readiness, digital literacy, modern technology roles |
| **4. Cybersecurity and Risk** | 15% | Policy compliance (SIMM 5300), security governance |
| **5. Service Delivery** | 15% | Digital service maturity, user-centered design |
| **6. Funding and Portfolio Management** | 15% | Project management maturity, Stage 1-ready projects |

### C.2 Scoring Methodology (Summary)

**Maturity Scale (1-5):**
- **1 (Initial):** Ad hoc, reactive, no formal processes
- **2 (Emerging):** Basic awareness, inconsistent practices
- **3 (Developing):** Defined processes, partial implementation
- **4 (Managed):** Consistent execution, measurable outcomes
- **5 (Optimized):** Continuous improvement, industry-leading

**Readiness Tiers:**
- **Tier 1 (4.0-5.0):** Ready Now — Priority funding for high-impact projects
- **Tier 2 (3.0-3.9):** Near-Ready — Conditional funding with capability-building
- **Tier 3 (2.0-2.9):** Developing — Capacity-building grants, not project funding
- **Tier 4 (1.0-1.9):** Early Stage — Foundational organizational development

*For complete scoring rubrics with detailed examples, see [Enhanced Readiness Assessment](readiness-assessment/enhanced-readiness-assessment.md).*

---

## Appendix D: Glossary

**ADKAR:** Awareness, Desire, Knowledge, Ability, Reinforcement - Change management model

**AGPA:** Associate Governmental Program Analyst - Civil service classification

**API:** Application Programming Interface - Software intermediary allowing applications to communicate

**Breakthrough Fund:** California Breakthrough Modernization Fund - Revolving fund with private-sector seed capital and efficiency savings reinvestment

**CalAcademy:** California training platform managed by ODI for state employee skill development

**CCPA:** California Consumer Privacy Act - State data privacy law

**CDO:** Chief Data Officer

**CDT:** California Department of Technology

**Chief Deputy Director for E3:** Department-level position with operational responsibility for efficiency and effectiveness modernization

**CJIS:** Criminal Justice Information Services - FBI standards for data security and exchange

**DevOps:** Development and Operations - Software development methodology emphasizing collaboration and automation

**DOF:** Department of Finance

**E3:** Enterprise Efficiency and Effectiveness - Operational model creating forcing mechanism for government efficiency through institutional design

**ESB:** Enterprise Service Bus - Centralized integration platform (not adopted; Service Mesh preferred)

**FedRAMP:** Federal Risk and Authorization Management Program - Cloud security certification

**Fellowship:** Governor's Innovation Fellowship Program - 6-month cohort program developing modernization leaders

**FISMA:** Federal Information Security Management Act

**GovOps:** Government Operations Agency

**HL7 FHIR:** Health Level 7 Fast Healthcare Interoperability Resources - Health data exchange standard

**IaaS:** Infrastructure as a Service - Cloud computing model

**Independent Office:** Independent Office of State Data Governance - Cross-branch governance body

**KPI:** Key Performance Indicator

**MDM:** Master Data Management - Practices ensuring uniform, accurate data across systems

**MOU:** Memorandum of Understanding

**NIEM:** National Information Exchange Model - Criminal justice data standard

**NIST:** National Institute of Standards and Technology

**ODI:** Office of Data and Innovation

**OKR:** Objectives and Key Results - Goal-setting framework

**PaaS:** Platform as a Service - Cloud computing model

**PE:** Professional Engineer - Licensed engineering professional

**PG:** Professional Geologist - Licensed geoscience professional

**PIA:** Privacy Impact Assessment

**PPM:** Project Portfolio Management

**RDS:** Research Data Specialist - Civil service classification for data professionals

**RFI²:** Request for Innovative Ideas - Problem-based procurement method

**RFP:** Request for Proposals

**ROI:** Return on Investment

**SaaS:** Software as a Service - Cloud computing model

**Service Mesh:** Decentralized infrastructure layer handling service-to-service communication

**SIMM:** Statewide Information Management Manual - California IT policy

**SLA:** Service Level Agreement

**SME:** Subject Matter Expert

**SSA:** Staff Services Analyst - Civil service classification

**Strangler Pattern:** Legacy system modernization approach incrementally replacing components

**TMO:** Transformation Management Office - Central coordination function for modernization

**Undersecretary for E3:** Agency-level position with authority over technology, data governance, and performance management

**Zero Trust:** Security model requiring continuous verification, not one-time authentication

---

## Appendix E: References and Source Documents

### E.1 Source Documents Synthesized

**Original Enterprise Plan (E3 Concept):**
- Executive Brief
- Strategy Report (Parts 1-3)

**Rev1G3 (Product-Led Government):**
- Executive Brief
- Strategy Report (Parts 1-3)

**Rev2G3 (Data Governance):**
- Data Governance Main Brief
- Option B Detailed Implementation

**Rev3G3 (Integration Framework):**
- Executive Brief
- Strategic Plan
- Implementation Roadmap
- Operational Toolkit
- Future Vision

**Supporting Planning Documents:**
- Breakthrough Modernization Fund concept
- Fellowship Program Plan (Parts 1-2)
- Data Governance Teams structure

**Readiness Assessment:**
- Executive Summary
- Enhanced Readiness Assessment
- Implementation Guide
- Scale Background

### E.2 External References

**Government Modernization:**
- UK Government Digital Service (GDS) transformation model
- U.S. Digital Service playbooks
- 18F best practices
- VA modernization case studies
- Oklahoma tax system modernization (strangler pattern)
- Connecticut CDO Council model

**Technology Standards:**
- NIST Cybersecurity Framework
- NIST 800-53 Rev 5
- OpenAPI Specification 3.0
- HL7 FHIR R4
- NIEM 5.0
- OGC Standards

**Procurement and Contracting:**
- Executive Order N-04-19 (RFI² authority)
- Public Contract Code Section 6611
- Federal Technology Modernization Fund model
- Modular contracting best practices

**Data Governance:**
- Federal Data Strategy
- DAMA Data Management Body of Knowledge
- California Consumer Privacy Act (CCPA)
- Privacy Impact Assessment templates

**Change Management:**
- Prosci ADKAR methodology
- Kotter's 8-Step Change Model
- McKinsey digital transformation research

### E.3 Key Legislation and Executive Orders

**Existing:**
- Executive Order N-04-19 (RFI² authority)
- Government Code Section 12815 (ODI statutory mandate)
- California Consumer Privacy Act
- SIMM 5300 (IT security requirements)

**Proposed:**
- California Data Governance Act (establishing Independent Office)
- Executive Order establishing E3 framework and modular contracting cap
- Budget appropriations for Breakthrough Fund seed capital

---

## Appendix F: Budget and Financial Models

> **Cost Estimate Disclaimer:** The budget estimates in this appendix are preliminary planning figures based on comparable positions, programs, and initiatives. Actual costs will vary based on final position classifications, labor negotiations, market conditions, and implementation decisions. These estimates should be refined during detailed budget development with CalHR, Department of Finance, and agency budget offices. All figures are presented in current dollars; multi-year projections do not include inflation adjustments.

### F.1 E3 Position Costs

**Undersecretary for Efficiency and Effectiveness:**
- Annual Salary: $200K-$250K (competitive with private sector)
- Benefits and overhead (1.4x multiplier): $280K-$350K total loaded cost
- **8-12 positions statewide: $2.2M-$4.2M annually**

**Chief Deputy Director for Efficiency and Effectiveness:**
- Annual Salary: $150K-$180K
- Benefits and overhead (1.4x multiplier): $210K-$252K total loaded cost
- **30-40 positions statewide: $6.3M-$10.1M annually**

**Total E3 Leadership: $8.5M-$14.3M annually**

### F.2 Transformation Management Office

**Staffing (16-23 personnel):**
- Director: $250K loaded
- Senior Staff (5-7): $1.2M-$1.7M loaded
- Mid-level Staff (8-12): $1.4M-$2.1M loaded
- Support Staff (2-3): $250K-$375K loaded
- **Total TMO: $3.1M-$4.4M annually**

**Operating Costs:**
- Technology and tools: $500K annually
- Travel and events: $300K annually
- Training and development: $200K annually
- **Total operating: $1M annually**

**TMO Total Budget: $4.1M-$5.4M annually**

### F.3 Independent Office of State Data Governance

**One-Time Setup:**
- Facilities and infrastructure: $1M-$2M
- Technology platform: $1M-$2M
- Initial staffing and recruitment: $1M-$1M
- **Total setup: $3M-$5M**

**Annual Operating:**
- Executive Director/CDO and senior staff: $1M-$1.5M
- Policy and standards staff: $800K-$1.2M
- Legal and compliance: $400K-$600K
- Operations and support: $300K-$700K
- **Total annual: $2.5M-$4M**

### F.4 Governor's Innovation Fellowship

**Per Fellow Costs (6-month program):**
- Stipend/salary: $50K-$60K (6 months)
- Benefits: $15K-$18K
- Training and development: $5K-$7K
- Travel and expenses: $3K-$5K
- **Total per fellow: $73K-$90K (6 months)**

**Annual Program Costs (42 fellows/year, 2 cohorts):**
- Fellow costs: $3.1M-$3.8M
- Program administration: $500K-$700K
- Curriculum and training: $300K-$400K
- **Total annual: $3.9M-$4.9M**

### F.5 Data Governance Teams

**Standard Team (13-15 FTE):**
- Team Director (Senior Supervisor): $180K loaded
- Technical leads (2-3): $350K-$525K loaded
- Domain specialists (4-5): $500K-$625K loaded
- Data analysts (4-5): $340K-$425K loaded
- Support staff (2): $160K loaded
- **Total per team: $1.53M-$1.91M annually**

**Statewide Deployment (30-40 teams by Year 3):**
- **Total: $45.9M-$76.4M annually**

### F.6 Breakthrough Fund Capitalization

**Seed Investment:**
- State appropriation: $50M-$100M one-time
- Private sector match: $50M-$100M
- **Total initial fund: $100M-$200M**

**Year 1-2 Deployment:**
- 15-25 projects funded: $50M-$100M deployed
- Average project size: $2M-$4M

**Year 3 Self-Sustainability:**
- Documented savings: $250M+ cumulative
- 25% diverted to fund: $62.5M+
- Fund becomes 30-50% self-sustaining

### F.7 Five-Year Financial Summary

**Initial Investment (Years 1-2):**
- E3 positions: $17M-$29M (2 years)
- TMO: $8M-$11M (2 years)
- Independent Office: $8M-$13M (setup + 2 years operating)
- Fellowship: $8M-$10M (2 years)
- Data governance teams (pilot): $9M-$12M (2 years, 6-10 teams)
- Breakthrough Fund seed: $50M-$100M (state contribution)
- **Total initial investment: $100M-$175M**

**Ongoing Operating (Year 3+):**
- E3 positions: $8.5M-$14.3M annually
- TMO: $4.1M-$5.4M annually
- Independent Office: $2.5M-$4M annually
- Fellowship: $3.9M-$4.9M annually
- Data governance teams: $45.9M-$76.4M annually
- **Total annual operating: $65M-$105M**

**Return on Investment:**
- Year 3 documented savings: $250M+ cumulative
- Year 5 documented savings: $500M+ cumulative
- **5-Year Net ROI: $200M-$350M**

---

## Appendix G: Performance and Change Management Framework

### G.1 Multi-Tiered KPI Framework

California's modernization requires measurement at four distinct levels, from strategic citizen-facing outcomes to operational technical metrics, integrated with change management indicators.

**Tier 1: Statewide Strategic KPIs**

**Digital Service Adoption Rate**
- Current Baseline: 35-40%
- Year 2 Target: 45%
- Year 3 Target: 50%
- Year 5 Target: 65%
- Measurement: Percentage of transactions completable entirely online

**Citizen Satisfaction Score (CSAT)**
- Current Baseline: 65%
- Year 2 Target: 75%
- Year 5 Target: 85%
- Measurement: Post-transaction surveys (5-point scale)

**Cost Per Transaction**
- Current Baseline: Varies (in-person $15-25, phone $8-12, digital $0.50-2)
- Target: 50% reduction in average cost through digital channel shift

**Time-to-Value for New Services**
- Current Baseline: 18-36 months
- Year 2 Target: 12 months average
- Year 5 Target: 90 days for MVP, iterative enhancement thereafter

**Tier 2: Operational KPIs**

**System Availability**
- High criticality: 99.9% (< 9 hours downtime/year)
- Moderate criticality: 99.5% (< 44 hours downtime/year)
- Low criticality: 99.0% (< 88 hours downtime/year)

**API Response Times**
- Target: < 200ms for 95th percentile, < 500ms for 99th percentile

**Legacy System Reduction**
- Year 2: 10% reduction (40 systems)
- Year 3: 25% reduction cumulative
- Year 5: 40% reduction cumulative

**Data Sharing Agreements Executed**
- Year 2: +50 new agreements
- Year 5: 150+ total agreements

**Tier 3: Transformation Progress KPIs**

**Digital Maturity Score**
- Scale: 1-5 for each dimension (technology, workforce, process, data, citizen experience)
- Target: Agency average 3.5+ by Year 3, 4.0+ by Year 5

**Employee Adoption Rates**
- Target: 80% active usage within 6 months of deployment

**Training Completion Rates**
- Target: 100% of IT staff complete foundational track by Year 2

**Budget Variance**
- Target: 90%+ of projects within ±10% of approved budget

**Tier 4: Change Management KPIs**

**Employee Satisfaction with Modernization**
- Quarterly pulse surveys
- Target: Average 4.0+ (agree/strongly agree)
- Sample Questions:
  - "I understand why we are modernizing our systems and processes"
  - "I have the training and support I need to succeed with new tools"
  - "Modernization is improving my ability to serve citizens"

**Change Adoption Rate**
- Track process inventory status (legacy, in transition, modernized)
- Target: 60% of processes modernized by Year 5

**Innovation Metrics**
- 50+ experiments per year
- 30% pilot-to-production conversion rate
- Number of RFI² solicitations, sandbox experiments, hackathon participants

### G.2 OKR (Objectives and Key Results)

**Quarterly Cycle:**
1. Week 1: Leadership sets OKRs aligned with annual priorities
2. Weeks 2-11: Execute, weekly check-ins
3. Week 12: Score OKRs (0.0-1.0), retrospective, celebrate wins
4. Week 13: Plan next quarter incorporating learnings

**Scoring Philosophy:**
- 0.7-0.8 = Success (OKRs should be ambitious)
- 0.4-0.6 = Partial Success
- < 0.4 = Miss (investigate root causes)

**Transparency:**
- All OKRs published on public dashboard
- Quarterly reviews shared with executive leadership
- Annual compilation shows multi-year progress

**Example OKR (Year 1, Q2):**

**Statewide Objective:** Establish foundational E3 governance and demonstrate early value

**Key Result 1:** Deploy Undersecretary positions in 4 priority agencies with onboarding complete
- Measure: 4 positions filled and onboarded by June 30, 2026
- Owner: GovOps, ODI

**Key Result 2:** Launch 10 pilot projects with at least 3 showing measurable improvements
- Measure: 3+ pilots demonstrating 20%+ efficiency gains or citizen satisfaction improvements
- Owner: TMO

**Key Result 3:** Achieve 500 employees enrolled in Digital Accelerators program
- Measure: 500 enrollments across all tracks
- Owner: CDT, CalHR

### G.3 Public Dashboard

**Design Principles:**
- Simple, visual presentation for non-technical audiences
- Real-time or near-real-time data (updated weekly)
- Drill-down capability (statewide → agency → department → project)
- Mobile-responsive

**Dashboard Sections:**
1. Transformation Overview (progress toward targets, current OKR scores, major milestones)
2. Project Portfolio Health (total active projects, status breakdown, recent completions)
3. Agency Scorecards (digital maturity, key metrics, achievements)
4. Citizen Impact (services digitized, testimonials, savings achieved)
5. Innovation Highlights (RFI² solicitations, pilots, Fellow spotlights)

### G.4 Reporting Cadence

**Quarterly Executive Reports:**
- Audience: Governor, Agency Secretaries, Legislative leadership
- Content: Executive summary, KPI progress, financial summary, risk assessment, next quarter priorities, case studies
- Published within 3 weeks of quarter end

**Annual Transformation Report:**
- Comprehensive review of year's progress
- Lessons learned
- Updated multi-year roadmap
- Presented at national conferences (NASCIO, Code for America)

### G.5 Change Management: The ADKAR Model

Government digital transformation has an 80% failure rate, primarily due to cultural resistance. Technology is only 30% of the challenge; people and process represent 70%.

**ADKAR Framework:**
- **A**wareness of need for change
- **D**esire to support and participate
- **K**nowledge of how to change
- **A**bility to implement change
- **R**einforcement to sustain change

**Application:**

**Awareness:**
- Executive communications explaining "why modernize"
- Data on current state challenges (system age, costs, citizen satisfaction)
- Vision of future state benefits
- Regular town halls and listening sessions

**Desire:**
- Involve staff in co-design of solutions
- Address "what's in it for me"
- Celebrate early adopters and champions
- No-blame experimentation zones
- Union engagement and collaboration

**Knowledge:**
- Comprehensive training programs (Digital Accelerators, CalAcademy)
- Job aids and documentation
- Peer mentoring and communities of practice

**Ability:**
- Hands-on practice in sandbox environments
- Coaching and support during transition
- Protected learning time (20% of work hours)
- Gradual rollouts with support

**Reinforcement:**
- Recognition and rewards for adoption
- Performance incentives tied to modernization outcomes
- Ongoing support and continuous improvement
- Integration into performance evaluations

### G.6 Resistance Management

**Common Sources of Resistance:**
- Fear of job loss or role change
- Comfort with status quo
- Previous failed change attempts
- Lack of trust in leadership
- Insufficient training or support
- Unclear benefits

**Mitigation Strategies:**
- Transparent communication about job security
- Retraining and reskilling programs
- Early involvement in design
- Small wins demonstrating value
- Leadership visibility and commitment
- Adequate support resources

### G.7 Communication Strategy

**Audiences:**
- Executive leadership
- Department directors and managers
- Frontline staff
- Labor unions
- Legislature
- Citizens/stakeholders
- Media

**Channels:**
- Town halls and listening sessions
- Internal newsletters and emails
- Intranet and collaboration platforms
- Training events
- Success story publications
- Social media and press releases

**Messaging:**
- Consistent narrative about "why" and "what"
- Balanced reporting (successes and challenges)
- Recognition of individuals and teams
- Connection to mission and values
- Data-driven progress updates

### G.8 Risk Mitigation Matrix

The following table identifies key risks to the modernization initiative and mitigation strategies:

| Risk | Impact | Likelihood | Mitigation Strategy |
|------|--------|------------|---------------------|
| **Independent Office legislation delayed** | HIGH | MEDIUM | Early stakeholder engagement, concurrent legislative and planning work, interim steering committee maintaining momentum if needed |
| **Resistance to change from entrenched interests** | HIGH | HIGH | Protected learning time, no-blame experimentation zones, union engagement early, quick wins demonstrating value, Readiness Assessment identifying concerns |
| **Political transitions disrupting momentum** | MEDIUM | MEDIUM | Cross-branch Independent Office structure, bipartisan legislative framing, embedded governance surviving transitions, early wins demonstrating value across political spectrum |
| **Vendor dependencies and lock-in** | MEDIUM | MEDIUM | Open standards requirements, API-first architecture, modular contracting $15M cap, competitive procurement, avoid proprietary platforms |
| **Fellowship talent retention challenges** | MEDIUM | MEDIUM | Preferential hiring pathways, executive duty statement integration, ongoing SME network engagement, competitive advancement opportunities, alumni network maintaining connections |
| **Low-readiness departments failing E3 deployment** | MEDIUM | LOW | Readiness Assessment-based deployment sequencing, capacity building before E3 assignment, Tier 3-4 departments receive intensive training before projects, realistic timelines |
| **GovOps coordination challenges across agencies** | MEDIUM | LOW | Clear TMO charter, adequate staffing, Governor's Office support, Statewide E3 Council peer accountability, respect for agency autonomy |
| **Breakthrough Fund project failures** | LOW | MEDIUM | Portfolio diversification (70/20/10 risk allocation), stage-gate governance stopping failing projects early, metrics-driven decisions, no sunk cost fallacy |

---

## Appendix H: Technology Architecture Details

> **Appendix Summary:** This appendix provides comprehensive technical architecture guidance across six domains: API Management (H.1), Legacy Modernization (H.2), Cloud Strategy (H.3), Cybersecurity (H.4), Agentic Data Systems (H.5), and Technology Standards (H.6). Use as reference for technical implementation decisions.

This appendix provides comprehensive technical architecture guidance for California's enterprise modernization initiative, incorporating and expanding upon the Technology Standards Catalog.

### H.1 API Management Strategy

**Centralized API Gateway:**

A unified API gateway provides the entry point for all API traffic, enabling consistent security, monitoring, and governance across California's digital services.

**Core Capabilities:**
- Single entry point for all API traffic (internal and external)
- Enforces authentication, authorization, rate limiting, and logging
- Provides analytics on API usage patterns and performance
- Enables A/B testing and canary deployments for continuous improvement
- Supports versioning and backward compatibility

**Developer Portal:**

A comprehensive developer portal democratizes access to California's government services through well-documented, self-service APIs.

**Features:**
- Unified catalog of all state government APIs (searchable by function, agency, data type)
- Interactive API documentation (OpenAPI/Swagger specifications)
- Self-service API key provisioning with approval workflows
- Code samples and SDKs in multiple languages (Python, JavaScript, Java, C#)
- Sandbox environments for testing without production impact
- Support forums and ticketing system for developer assistance
- Usage dashboards showing consumption and performance

**API Classification:**

California establishes three tiers of APIs with appropriate access controls and service levels:

**Public APIs:** Available to any consumer (developers, researchers, businesses, citizens)
- Minimal authentication (API key registration with email verification)
- Generous rate limits (10,000 requests/day per key)
- Published on public developer portal (developer.ca.gov)
- Examples: Business registry lookup, public datasets, geospatial data, licensing information

**Partner APIs:** Available to approved external organizations (contractors, research institutions, local governments)
- OAuth 2.0 authentication with formal approval process
- Moderate rate limits (100,000 requests/day)
- Formal SLA and dedicated support channels
- Examples: Case management systems, benefit eligibility verification, identity verification

**Internal APIs:** Available only to state government systems and authorized staff
- Mutual TLS authentication with certificate management
- High rate limits (1,000,000 requests/day)
- Internal developer portal with additional security documentation
- Examples: PII data access, financial systems, law enforcement databases

**Deployment Targets:** 75 APIs by Year 1, 150 by Year 2, 200 by Year 3 (final distribution: 50 public, 50 partner, 100 internal)

### H.2 Legacy System Modernization

**Strangler Pattern (Preferred Approach):**

California adopts the strangler pattern for legacy modernization, avoiding risky "big bang" replacements in favor of incremental transformation while maintaining operational continuity.

**Process:**
1. **Create API Facade:** Wrap legacy system with API layer providing modern interface to old functionality
2. **Build New Microservice:** Develop cloud-native service replicating one discrete function
3. **Route Intelligently:** Direct new requests to microservice while legacy requests continue to old system
4. **Migrate Gradually:** Incrementally shift functionality to new services based on usage patterns and risk assessment
5. **Decommission Legacy:** Remove legacy system components when usage reaches zero and all functionality migrated

**Benefits:**
- **Lower Risk:** No catastrophic cutover; system remains operational throughout migration
- **Continuous Value:** Users experience improvements incrementally rather than waiting years
- **Course Correction:** Ability to pause, adjust strategy, or pivot based on learnings
- **Service Availability:** Maintains citizen access throughout modernization process
- **Resource Flexibility:** Can accelerate or slow migration based on resource availability and competing priorities

**Sunset Timelines:**

California establishes clear timelines for legacy system retirement based on technical debt and criticality:

- **High technical debt + high criticality:** 2-year maximum lifespan from assessment
- **High technical debt + medium criticality:** 3-year maximum
- **Medium technical debt:** 5-year maximum
- **Automatic review trigger:** Systems exceeding planned lifecycle must justify continuation annually

**Modernization Portfolio Targets:**
- **Year 1:** Complete comprehensive assessment across all departments; decommission 10% of legacy systems (40 systems)
- **Year 2:** Decommission 10% more (20% cumulative); complete API facades for 50 high-priority systems
- **Year 3:** Decommission 10% more (30% cumulative); achieve 50% reduction in legacy technical debt
- **Years 4-5:** Achieve 40% total legacy reduction target while maintaining operational stability

### H.3 Cloud Strategy

**Hybrid Cloud with On-Premises Redundancy:**

To protect state business operations in the event of internet outage or cloud service disruption, California adopts a hybrid cloud strategy that maintains on-premises redundancy for critical systems.

**Architecture Principles:**

**Cloud-First for New Development:** All new systems deployed to cloud unless specific exception granted based on:
- Data sovereignty requirements (specific statutes mandating on-premises storage)
- Latency requirements incompatible with cloud architecture
- Cost analysis showing on-premises more cost-effective over 5-year horizon
- Security requirements exceeding cloud provider capabilities

**Critical System Redundancy:** Mission-critical systems maintain on-premises backup capability enabling continued operations during cloud outages.

**Hybrid Connectivity:** Secure, redundant connections between cloud and on-premises infrastructure:
- Multiple dedicated interconnects from different providers
- VPN backup connectivity
- Automatic failover between connectivity paths
- Continuous monitoring of connection health

**Multi-Cloud Strategy:** Avoid single cloud vendor lock-in through multi-cloud deployment where feasible:
- Critical applications deployed across multiple cloud providers
- Containerized workloads enabling portability
- Infrastructure-as-Code supporting multi-cloud deployment
- Careful analysis of multi-cloud complexity vs. flexibility benefits

**Critical Systems Requiring On-Premises Redundancy:**

Examples of systems that must maintain on-premises operational capability:

- **Emergency Services:** 911 dispatch, CAL FIRE coordination, emergency management systems, emergency alert systems
- **Law Enforcement:** Criminal justice information systems, arrest and booking systems, warrant management
- **Public Safety:** Prison management systems, probation and parole tracking, sex offender registry
- **Benefits Delivery:** CalFresh, Medi-Cal eligibility, unemployment insurance payments, child support
- **Critical Infrastructure:** Water management systems, power grid coordination, transportation management
- **Financial Systems:** Payroll processing, tax collection, treasury operations, pension management

**Implementation Strategy:**
- **Primary workloads run in cloud** for scalability, elasticity, and cost efficiency
- **Critical data replicated to on-premises systems** in near-real-time (typically < 5 minute lag)
- **On-premises systems capable of maintaining operations** during internet disruption (degraded capacity acceptable)
- **Regular failover testing** (quarterly minimum) to ensure redundancy effectiveness
- **Automated failback** when cloud connectivity restored, with data reconciliation
- **Clear procedures** for manual intervention if automated failover fails

**Cloud Provider Requirements:**
- FedRAMP-certified cloud providers (AWS GovCloud, Microsoft Azure Government, Google Cloud Platform)
- FISMA compliance appropriate to data sensitivity (Moderate or High)
- StateRAMP (California-specific requirements including data residency, audit access, breach notification)
- SLA guarantees: 99.9% uptime for production services, 99.99% for critical systems
- Geographic redundancy within California or western United States where possible

**Cloud-Native Architecture:**

California adopts modern cloud-native patterns to maximize cloud benefits:

- **Containers and Orchestration:** Docker containers managed by Kubernetes enabling portability and scaling
- **Serverless Computing:** AWS Lambda, Azure Functions, or Google Cloud Functions for event-driven workloads
- **Managed Services:** Leverage cloud provider services reducing operational overhead (managed databases, message queues, caching)
- **Infrastructure as Code (IaC):** Terraform or CloudFormation for repeatable, version-controlled infrastructure
- **Automated Backup and Disaster Recovery:** Cloud-native backup with cross-region replication
- **Auto-Scaling:** Automatically adjust capacity based on demand
- **Immutable Infrastructure:** Replace rather than update infrastructure components

**Migration Approach:**
- **Prioritize high-cost, low-complexity workloads first** (quick wins demonstrating value)
- **Use lift-and-shift for initial migration**, then re-architect for cloud-native over time
- **Implement strong cloud governance:** Cost management, security controls, compliance monitoring, tagging standards
- **Data center consolidation** as workloads migrate, reducing facilities costs
- **Hybrid period of 3-5 years** recognizing gradual transition

**Target:** 50% of workloads in cloud by Year 3, with all critical systems maintaining on-premises redundancy

### H.4 Cybersecurity Architecture

**Zero Trust Architecture:**

California transitions from perimeter-based security to Zero Trust, recognizing that threats exist both outside and inside the network.

**Core Principles:**
- **Identity-based access:** Authentication based on user/service identity, not network location
- **Least privilege:** Minimum necessary access for users and systems
- **Assume breach:** Design assuming attackers have network access
- **Verify explicitly:** Authenticate and authorize every access request
- **Continuous verification:** Re-authenticate throughout session, not just at login

**Implementation:**

**Single Federated Identity System:**
- Unified identity management for all state services and employees
- Multi-factor authentication (MFA) required for all accounts
- Risk-based authentication adjusting requirements based on user behavior and context
- Single sign-on (SSO) reducing password fatigue and improving user experience
- Integration with CalHR for employee lifecycle management

**Access Control:**
- Role-based access control (RBAC) with regular access reviews
- Attribute-based access control (ABAC) for fine-grained permissions
- Just-in-time (JIT) access for privileged operations
- Session recording for auditing high-risk actions

**Network Segmentation:**
- Micro-segmentation limiting lateral movement
- Software-defined perimeter (SDP) controlling network access
- East-west traffic inspection (not just north-south)

**Standards Compliance:**

**NIST Cybersecurity Framework:**
- Identify, Protect, Detect, Respond, Recover functions
- Maturity assessment and roadmap for improvement
- Alignment with federal requirements for interoperability

**NIST 800-53 Security and Privacy Controls:**
- Moderate or High baseline depending on data sensitivity
- Continuous monitoring and control assessment
- Documentation of control implementation and effectiveness

**California-Specific SIMM 5300 Requirements:**
- State-specific security and privacy requirements
- Information security program requirements
- Incident reporting obligations

**Data Protection:**

**Encryption:**
- **In Transit:** TLS 1.3 for all network communications (TLS 1.2 minimum)
- **At Rest:** AES-256 encryption for all databases and file storage
- Key management via Hardware Security Modules (HSM) or cloud key management services
- Regular key rotation following NIST guidelines

**PII Protection:**
- Automatic PII detection and classification
- Redaction of PII in logs and error messages
- Tokenization for PII in non-production environments
- Data loss prevention (DLP) tools monitoring PII movement

**Audit Logging:**
- All data access logged with user, timestamp, data accessed, action performed
- Logs retained for 7 years (or longer for high-sensitivity data)
- Centralized log aggregation and analysis
- Tamper-proof log storage
- Regular review of access patterns and anomalies

**Security Operations:**

**24/7 Security Monitoring:**
- Security Information and Event Management (SIEM) aggregating logs from all systems
- Security Operations Center (SOC) staffed 24/7/365
- Automated threat detection using machine learning
- Integration with threat intelligence feeds

**Automated Threat Detection and Response:**
- Intrusion detection and prevention systems (IDS/IPS)
- Endpoint detection and response (EDR)
- User and entity behavior analytics (UEBA)
- Automated response to common threats (e.g., blocking suspicious IPs)

**Incident Response:**
- Documented incident response plan with defined roles and procedures
- Tabletop exercises quarterly testing response procedures
- Forensic capabilities for investigation
- Communication protocols for breach notification
- Post-incident reviews and lessons learned

**Vulnerability Management:**
- Continuous vulnerability scanning of all systems
- Automated patching for non-critical systems
- Expedited patching for critical vulnerabilities (48-hour target)
- Regular penetration testing (annual for critical systems, biennial for others)
- Bug bounty program encouraging responsible disclosure

**Security Awareness:**
- Annual security training required for all employees
- Monthly security tips and phishing simulations
- Specialized training for developers (secure coding) and administrators (hardening)
- Recognition program for security champions

### H.5 Staff Empowerment for Agentic Data Systems

**Vision:**

Enable California state staff to create AI-powered data workflows using state-approved patterns and shared infrastructure, accelerating data analysis and decision-making while maintaining security, privacy, and quality standards.

**State-Approved Design Patterns:**

California develops and maintains a library of approved agentic design patterns that staff can use to build data workflows safely:

**Data Analysis and Visualization:**
- Automated data quality checking and reporting
- Natural language queries translating to SQL or API calls
- Automated dashboard generation based on data characteristics
- Anomaly detection and alerting

**Document Processing and Extraction:**
- Intelligent form data extraction from PDFs and images
- Document classification and routing
- Summarization of lengthy reports and submissions
- Translation of documents into multiple languages

**Workflow Automation and Case Management:**
- Automated case prioritization based on urgency and complexity
- Intelligent case routing to appropriate staff
- Automated status updates and notifications
- Predictive analytics for case outcomes

**Knowledge Base and Expert Systems:**
- Chatbots answering citizen questions based on policy documents
- Decision support systems incorporating regulations and best practices
- Automated policy impact analysis
- Institutional knowledge capture from retiring staff

**Standards and Guardrails:**

Every agentic design pattern must meet California's requirements for:

**Content Classification:**
- Clear labeling of AI-generated content
- Distinction between AI analysis and human judgment
- Appropriate disclaimers for citizen-facing content

**Accuracy Requirements:**
- Validation thresholds for AI outputs (typically 95%+ accuracy for production use)
- Human review requirements for high-stakes decisions
- Fallback to human judgment when confidence below threshold

**Bias Testing:**
- Documented testing for demographic bias
- Disparate impact analysis where applicable
- Mitigation strategies for identified biases

**Transparency:**
- Explainability of AI decisions (how conclusion reached)
- Data provenance (what data informed the analysis)
- Model cards documenting capabilities and limitations

**Logging and Audit:**
- All AI interactions logged for audit and improvement
- Feedback mechanisms capturing accuracy and usefulness
- Regular review of AI performance and drift

**Version Control:**
- Documented versions of prompts, models, and training data
- Rollback capability when new versions underperform
- A/B testing of model improvements

**Shared Infrastructure:**

California provides shared infrastructure enabling staff to build agentic workflows without individual departments procuring and managing AI systems:

**CDT-Operated Enterprise AI Platform:**
- Centralized access to approved large language models (LLMs)
- Compute resources for training and inference
- Managed services for common AI tasks (OCR, translation, sentiment analysis)
- Unified billing and cost allocation
- Enterprise security and compliance controls

**Departmental Sandboxes:**
- Isolated environments for experimentation and development
- Access to production data copies (anonymized where appropriate)
- Testing framework for validating accuracy and performance
- Promotion pathway from sandbox to pilot to production

**Template Library:**
- Pre-built templates for common use cases
- Customization guidance for department-specific needs
- Community contributions from across state government
- Documentation and training materials

**Deployment Process:**

California establishes a streamlined pathway from idea to production:

1. **Sandbox Development:** Staff build and test agentic workflow in departmental sandbox (days/weeks)
2. **Testing and Validation:** Automated testing validates accuracy, bias, security (1-2 weeks)
3. **Security Scan:** Automated security scanning checks for vulnerabilities and policy compliance (days)
4. **Peer Review:** Review by E3 data governance team ensuring standards compliance (1 week)
5. **Pilot Deployment:** Limited rollout to small user group with monitoring (4-8 weeks)
6. **Production Deployment:** Full rollout with ongoing monitoring and improvement (ongoing)

**Timeline:** Sandbox to production in 8-12 weeks for typical workflow (versus 12-18 months traditional system development)

**Expected Impact:**
- Staff able to automate 20-30% of routine data analysis tasks
- Faster insights enabling more responsive policy and operations
- Reduced backlog of data requests and analysis needs
- Upskilling of workforce in AI literacy and capabilities
- Democratization of data analysis beyond specialized analysts

### H.6 Technology Standards Catalog

#### H.6.1 API Standards

**Required Standards (All APIs):**
- RESTful design following HTTP semantics
- JSON as primary data format (XML supported for legacy compatibility)
- HTTPS only (no unencrypted HTTP)
- Versioning in URL path (e.g., /api/v2/permits)
- Pagination for list endpoints (maximum 100 items per page)
- Standard error responses with HTTP status codes and messages
- OpenAPI 3.0 specification for all APIs

**Authentication and Authorization:**
- OAuth 2.0 for external consumers (citizens, businesses, third-party developers)
- Mutual TLS for high-security government-to-government APIs
- API keys with rotation requirements (maximum 90-day validity)
- Role-based access control (RBAC) aligned with data sensitivity

**Data Protection:**
- TLS 1.3 encryption for all API traffic
- PII redaction in logs and error messages
- Rate limiting to prevent abuse (varies by API classification)
- IP whitelisting for high-sensitivity APIs

**Performance Requirements:**
- < 200ms average response time (95th percentile)
- < 500ms maximum response time (99th percentile)
- 99.95% availability for production APIs
- Graceful degradation under load

#### H.6.2 Data Exchange Standards

**Health and Human Services:**
- HL7 FHIR (Fast Healthcare Interoperability Resources) for health data exchange
- ICD-10 for diagnosis coding
- CPT for treatment and service coding
- LOINC for laboratory observations

**Justice and Corrections:**
- NIEM (National Information Exchange Model) for criminal justice data
- UCR (Uniform Crime Reporting) for crime statistics
- CJIS (Criminal Justice Information Services) standards for security

**Education:**
- CEDS (Common Education Data Standards) for enrollment, graduation, assessment
- SIF (Schools Interoperability Framework) for student information systems

**Geospatial:**
- OGC Standards (Open Geospatial Consortium) for GIS interoperability
- USNG (United States National Grid) for location referencing

#### H.6.3 Cybersecurity Standards

**Framework:**
- NIST Cybersecurity Framework (Identify, Protect, Detect, Respond, Recover)
- NIST 800-53 security and privacy controls
- California SIMM 5300 requirements

**Specific Controls:**
- DISA STIGs for configuration standards
- Zero Trust Architecture principles
- Encryption: TLS 1.3 (transit), AES-256 (at rest)
- Multi-factor authentication for all administrative access
- Security logging and monitoring (SIEM)
- Regular vulnerability scanning and penetration testing
- Incident response plan and tabletop exercises

#### H.6.4 Cloud Standards

**Approved Cloud Providers:**
- AWS GovCloud
- Microsoft Azure Government
- Google Cloud Platform (with appropriate certifications)

**Required Certifications:**
- FedRAMP Authorized (Moderate or High depending on data sensitivity)
- FISMA compliance
- StateRAMP (California-specific requirements)

**Architecture Principles:**
- Hybrid cloud with on-premises redundancy for critical systems
- Cloud-native design (containers, serverless, managed services) where appropriate
- Multi-cloud strategy to avoid vendor lock-in
- Infrastructure as Code (IaC) using Terraform or CloudFormation
- Automated backup and disaster recovery

---

## Version History

| Version | Date | Description |
|---------|------|-------------|
| Executive Draft v1.0 | December 2025 | Initial executive draft with Appendices B-H |

---

**Document Version:** Executive Draft v1.0
**Date:** December 2025
**Prepared for:** Governor's Office, Office of Data and Innovation, Government Operations Agency

---

*End of California Enterprise Modernization Plan - Technical Appendices*
